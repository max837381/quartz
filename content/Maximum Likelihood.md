---
title: Maximum Likelihood
date created: "Wednesday, February 8th 2023, 12:08:06 pm"
date modified: "Thursday, May 25th 2023, 1:25:20 am"
---

Maximum Likelihood

Without the i.i.d assumption we can't write it as a product

Without i.i.d you can still use maximum likelihood but it is more complicated

Likelihood function: $$L (\beta) = f\_{y|X}$$

Maximum likelihood estimator for a certain $\beta_0$ maximizes the probability of obtaining the data you have

Second derivative of the log lieklihood function at the maximum likedlihood estiamte

Maximum Likelihood can be used in both [Bayesian Statistics](Bayesian%20Statistics.md) and [Frequentist Statistics](Frequentist%20Statistics.md)

There is an arbitrary constant that means we can change the curve up and down without changing the shape

FIsher thought of it as a frequentist inferential method

Also approximate Bayesian method

Standard error is the square root of the variance

Estimated SE is the estimated square root of the variance of the random variable

Variance scale 

$\Large y_i$ = family income

SD would be in dollars \<- speical case 

* Same as data scale

Variance would be in dollars 

* (data scale)$^2$ 

![Screenshot 2023-02-08 at 12.14.44 PM.png](Image%20Bank/Screenshot%202023-02-08%20at%2012.14.44%20PM.png)

Red line = n = 403/2 (less data)
Green line = n = 403 (more data)

Second derivative of these log likelihood functions at theta_MLE would be negative

Thus we would multiply it by -1

Second derivative = strength of curvature

As n goes up the abdsolute value of the 2nd derivative would be gets bigger

as n goe sup then -1 * second derivative would also go up\*

As n increases information in y about theta increases

[Observed Information](Observed%20Information.md)
